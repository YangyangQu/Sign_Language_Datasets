![image](https://github.com/YangyangQu/Sign_Language_Datasets/assets/44865046/417e2d25-5f6f-4b61-a7fd-4eec59005979)![image](https://github.com/YangyangQu/Sign_Language_Datasets/assets/44865046/77badc4e-5bce-4c54-80e3-cd6a9d9c100f)# Sign-Language-Dataset
## This repository collects some common sign language recognition datasets.
Isolated sign language recognition datasets:
| Dataset | Sources | Paper Link | Download Link | Size | Type | Country | 
|-----|-----|-----|-----|-----|-----|-----|
| 内容1 | 内容2 | 内容3 |内容1 | 内容2 | 内容3 |内容1 | 



| 列1 | 列2 |
|-----|-----|
| 内容1 | 内容2 |
*WLASL: 14,289, 3,916, and 2,878 video segments in the train, dev, and test splits, respectively. [Link](https://dxli94.github.io/WLASL/)

+MSASL: 16,054, 5,287, and 4,172 video segments in the train, dev, and test splits, respectively. [Link](https://www.microsoft.com/en-us/research/project/ms-asl/)
-NMFs-CSL: 25,608 and 6,402 video segments in the train and test splits, respectively. [Link]
SLR500: 90,000 and 35,000 video segments in the train and test splits, respectively. [Link]
Slovo: 15,300 and 5,100 video segments in the train and test splits, respectively. [Link]
BOBSL: 993,000, 20,000, 165,000 video segments in train, val and test splits, respectively. [Link]
Continue sign language recognition datasets:

Phoenix-2014: 5,672, 540 and 629 video segments in the train, dev, and test splits, respectively. [Link]
Phoenix-2014T: 7,096, 519 and 642 video segments in train, dev and test splits, respectively. [Link]
Sign language translation datasets:

Phoenix-2014T: 7,096, 519 and 642 video segments in train, dev and test splits, respectively. [Link]
CSL-Daily: 18,401, 1,077 and 1,176 video segments in train, dev and test splits, respectively. [Link]
OpenASL: 96,476, 966 and 975 video segments in train, val and test splits, respectively. [Link]
How2Sign: 31,128, 1,741, 2,322 video segments in train, val and test splits, respectively. [Link]
BOBSL: 993,000, 20,000, 165,000 video segments in train, val and test splits, respectively. [Link]
