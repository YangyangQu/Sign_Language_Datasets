This repository collects some common sign language recognition datasets.
Isolated sign language recognition datasets:

WLASL: 14,289, 3,916, and 2,878 video segments in the train, dev, and test splits, respectively. [Link]
MSASL: 16,054, 5,287, and 4,172 video segments in the train, dev, and test splits, respectively. [Link]
NMFs-CSL: 25,608 and 6,402 video segments in the train and test splits, respectively. [Link]
SLR500: 90,000 and 35,000 video segments in the train and test splits, respectively. [Link]
Slovo: 15,300 and 5,100 video segments in the train and test splits, respectively. [Link]
BOBSL: 993,000, 20,000, 165,000 video segments in train, val and test splits, respectively. [Link]
Continue sign language recognition datasets:

Phoenix-2014: 5,672, 540 and 629 video segments in the train, dev, and test splits, respectively. [Link]
Phoenix-2014T: 7,096, 519 and 642 video segments in train, dev and test splits, respectively. [Link]
Sign language translation datasets:

Phoenix-2014T: 7,096, 519 and 642 video segments in train, dev and test splits, respectively. [Link]
CSL-Daily: 18,401, 1,077 and 1,176 video segments in train, dev and test splits, respectively. [Link]
OpenASL: 96,476, 966 and 975 video segments in train, val and test splits, respectively. [Link]
How2Sign: 31,128, 1,741, 2,322 video segments in train, val and test splits, respectively. [Link]
BOBSL: 993,000, 20,000, 165,000 video segments in train, val and test splits, respectively. [Link]
